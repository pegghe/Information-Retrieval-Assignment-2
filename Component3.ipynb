{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# Component 3: LSH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "sys.path.append(\"Components\")\n",
    "from lsh import build_lsh_from_vectors, lsh_query, lsh_candidates, _cosine_similarities\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vectors = np.load(\"Data/processed/doc_vectors_w2v.npy\")\n",
    "metadata = pd.read_csv(\"Data/processed/doc_metadata.csv\")\n",
    "\n",
    "print(f\"Vectors: {doc_vectors.shape}\")\n",
    "print(f\"Metadata: {metadata.shape[0]} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpers",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helper_funcs",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ndcg_at_k(predicted, actual, k):\n",
    "    \"\"\"Normalized Discounted Cumulative Gain: rewards correct ordering.\"\"\"\n",
    "    dcg = sum([1/np.log2(i+2) for i, doc in enumerate(predicted[:k]) if doc in actual[:k]])\n",
    "    idcg = sum([1/np.log2(i+2) for i in range(min(len(actual), k))])\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "def compute_recall_at_k(predicted, actual, k):\n",
    "    \"\"\"Recall@k: fraction of true top-k found in predicted top-k.\"\"\"\n",
    "    return len(set(predicted[:k]) & set(actual[:k])) / k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exp1",
   "metadata": {},
   "source": [
    "## Experiment 1: Accuracy vs Efficiency (vary b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exp1_run",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_K = 10\n",
    "N_QUERIES = 50\n",
    "M = 128\n",
    "\n",
    "query_indices = np.random.choice(len(doc_vectors), N_QUERIES, replace=False)\n",
    "\n",
    "# Ground truth: exact nearest neighbors (cosine-based)\n",
    "exact_results = {}\n",
    "for qi in query_indices:\n",
    "    sims = _cosine_similarities(doc_vectors[qi], doc_vectors)\n",
    "    exact_results[qi] = np.argsort(-sims)[:TOP_K]\n",
    "\n",
    "results = []\n",
    "for b in [4, 8, 16, 32]:\n",
    "    print(f\"Testing b={b} bands\")\n",
    "    lsh_struct = build_lsh_from_vectors(doc_vectors, n_hashes=M, n_bands=b, random_state=42)\n",
    "    hyperplanes = lsh_struct[\"hyperplanes\"]\n",
    "    index = lsh_struct[\"index\"]\n",
    "    \n",
    "    recalls = []\n",
    "    ndcgs = []\n",
    "    candidate_ratios = []\n",
    "    query_times = []\n",
    "    \n",
    "    for qi in query_indices:\n",
    "        # Get candidates\n",
    "        proj_q = hyperplanes @ doc_vectors[qi]\n",
    "        query_sig = (proj_q >= 0).astype(np.uint8)\n",
    "        candidates = lsh_candidates(query_sig, index)\n",
    "        candidate_ratios.append(len(candidates) / len(doc_vectors))\n",
    "        \n",
    "        t0 = time.perf_counter()\n",
    "        indices, _ = lsh_query(doc_vectors[qi], doc_vectors, hyperplanes, index, top_k=TOP_K)\n",
    "        query_times.append(time.perf_counter() - t0)\n",
    "        \n",
    "        recalls.append(compute_recall_at_k(indices, exact_results[qi], TOP_K))\n",
    "        ndcgs.append(compute_ndcg_at_k(indices, exact_results[qi], TOP_K))\n",
    "    \n",
    "    results.append({\n",
    "        \"method\": \"LSH\",\n",
    "        \"m_hashes\": M,\n",
    "        \"b_bands\": b,\n",
    "        \"r_rows\": M // b,\n",
    "        \"recall_at_k\": np.mean(recalls),\n",
    "        \"ndcg_at_k\": np.mean(ndcgs),\n",
    "        \"candidate_ratio\": np.mean(candidate_ratios),\n",
    "        \"query_time\": np.mean(query_times),\n",
    "        \"N\": len(doc_vectors),\n",
    "        \"dim\": doc_vectors.shape[1],\n",
    "    })\n",
    "\n",
    "df_exp1 = pd.DataFrame(results)\n",
    "print(\"\\n=== Experiment 1: Accuracy vs Efficiency ===\")\n",
    "display(df_exp1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exp2",
   "metadata": {},
   "source": [
    "## Experiment 2: Scaling with N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exp2_run",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_LIST = [1000, 2000, 5000, 10000, min(20000, len(doc_vectors))]\n",
    "TEST_QUERIES = 10\n",
    "BEST_B = 16\n",
    "\n",
    "scaling_results = []\n",
    "\n",
    "for N in N_LIST:\n",
    "    print(f\"Testing N={N}\")\n",
    "    X = doc_vectors[:N]\n",
    "    test_idx = np.random.choice(N, TEST_QUERIES, replace=False)\n",
    "    \n",
    "    t0 = time.perf_counter()\n",
    "    lsh_struct = build_lsh_from_vectors(X, n_hashes=M, n_bands=BEST_B, random_state=42)\n",
    "    build_t = time.perf_counter() - t0\n",
    "    \n",
    "    q_times = []\n",
    "    for qi in test_idx:\n",
    "        t1 = time.perf_counter()\n",
    "        lsh_query(X[qi], X, lsh_struct[\"hyperplanes\"], lsh_struct[\"index\"], top_k=TOP_K)\n",
    "        q_times.append(time.perf_counter() - t1)\n",
    "    \n",
    "    scaling_results.append({\n",
    "        \"method\": \"LSH\",\n",
    "        \"N\": N,\n",
    "        \"dim\": X.shape[1],\n",
    "        \"build_time\": build_t,\n",
    "        \"query_time\": np.mean(q_times),\n",
    "    })\n",
    "\n",
    "df_exp2 = pd.DataFrame(scaling_results)\n",
    "print(\"\\n=== Experiment 2: Scaling with N ===\")\n",
    "display(df_exp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exp3",
   "metadata": {},
   "source": [
    "## Experiment 3: Scaling with Dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exp3_run",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM_LIST = [50, 100, 200]\n",
    "N_SAMPLE = 10000\n",
    "TEST_QUERIES = 10\n",
    "\n",
    "dim_results = []\n",
    "X_sample = doc_vectors[:N_SAMPLE]\n",
    "\n",
    "for d in DIM_LIST:\n",
    "    print(f\"Testing d={d}\")\n",
    "    X = X_sample[:, :d]\n",
    "    test_idx = np.random.choice(N_SAMPLE, TEST_QUERIES, replace=False)\n",
    "    \n",
    "    # Adjust m to be divisible by b\n",
    "    m = ((d * 2) // BEST_B) * BEST_B\n",
    "    m = max(BEST_B, min(256, m))\n",
    "    \n",
    "    t0 = time.perf_counter()\n",
    "    lsh_struct = build_lsh_from_vectors(X, n_hashes=m, n_bands=BEST_B, random_state=42)\n",
    "    build_t = time.perf_counter() - t0\n",
    "    \n",
    "    q_times = []\n",
    "    for qi in test_idx:\n",
    "        t1 = time.perf_counter()\n",
    "        lsh_query(X[qi], X, lsh_struct[\"hyperplanes\"], lsh_struct[\"index\"], top_k=TOP_K)\n",
    "        q_times.append(time.perf_counter() - t1)\n",
    "    \n",
    "    dim_results.append({\n",
    "        \"method\": \"LSH\",\n",
    "        \"N\": N_SAMPLE,\n",
    "        \"dim\": d,\n",
    "        \"build_time\": build_t,\n",
    "        \"query_time\": np.mean(q_times),\n",
    "    })\n",
    "\n",
    "df_exp3 = pd.DataFrame(dim_results)\n",
    "print(\"\\n=== Experiment 3: Scaling with Dimensionality ===\")\n",
    "display(df_exp3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save_results",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = \"Data/results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "df_exp1.to_csv(f\"{results_dir}/lsh_accuracy_efficiency.csv\", index=False)\n",
    "df_exp2.to_csv(f\"{results_dir}/lsh_scaling_N.csv\", index=False)\n",
    "df_exp3.to_csv(f\"{results_dir}/lsh_scaling_dim.csv\", index=False)\n",
    "\n",
    "print(\"âœ“ All LSH results saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Recall vs Candidate Ratio\n",
    "axes[0,0].plot(df_exp1[\"candidate_ratio\"], df_exp1[\"recall_at_k\"], 'o-', linewidth=2)\n",
    "axes[0,0].set(xlabel=\"Candidate Ratio\", ylabel=\"Recall@10\", \n",
    "              title=\"LSH: Accuracy vs Efficiency\")\n",
    "axes[0,0].grid(alpha=0.3)\n",
    "\n",
    "# nDCG vs Candidate Ratio\n",
    "axes[0,1].plot(df_exp1[\"candidate_ratio\"], df_exp1[\"ndcg_at_k\"], 's-', \n",
    "               linewidth=2, color='orange')\n",
    "axes[0,1].set(xlabel=\"Candidate Ratio\", ylabel=\"nDCG@10\", \n",
    "              title=\"LSH: Ranking Quality\")\n",
    "axes[0,1].grid(alpha=0.3)\n",
    "\n",
    "# Scaling with N\n",
    "ax2 = axes[1,0]\n",
    "ax2.plot(df_exp2[\"N\"], df_exp2[\"build_time\"], 'o-', label=\"Build\", linewidth=2)\n",
    "ax2_twin = ax2.twinx()\n",
    "ax2_twin.plot(df_exp2[\"N\"], df_exp2[\"query_time\"], 's-', color='orange', \n",
    "              label=\"Query\", linewidth=2)\n",
    "ax2.set(xlabel=\"N (documents)\", ylabel=\"Build Time (s)\", \n",
    "        title=\"LSH: Scaling with N\")\n",
    "ax2_twin.set_ylabel(\"Query Time (s)\")\n",
    "ax2.legend(loc='upper left')\n",
    "ax2_twin.legend(loc='upper right')\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "# Scaling with Dim\n",
    "ax3 = axes[1,1]\n",
    "ax3.plot(df_exp3[\"dim\"], df_exp3[\"build_time\"], 'o-', label=\"Build\", linewidth=2)\n",
    "ax3_twin = ax3.twinx()\n",
    "ax3_twin.plot(df_exp3[\"dim\"], df_exp3[\"query_time\"], 's-', color='orange', \n",
    "              label=\"Query\", linewidth=2)\n",
    "ax3.set(xlabel=\"Dimensionality\", ylabel=\"Build Time (s)\", \n",
    "        title=\"LSH: Scaling with Dimensions\")\n",
    "ax3_twin.set_ylabel(\"Query Time (s)\")\n",
    "ax3.legend(loc='upper left')\n",
    "ax3_twin.legend(loc='upper right')\n",
    "ax3.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{results_dir}/lsh_benchmark_summary.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "informationretrieval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}